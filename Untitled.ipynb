{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "from joblib import load\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create a set with stopwords from ntkl and personalized dict\n",
    "stops = set(stopwords.words(\"english\"))   \n",
    "custom_words = ['use','would','x','want','way','like','work','get','one',\n",
    "                'new','code','need','someth','test','good','make','always',\n",
    "                'problem','take','best','anyone','given','look','also',\n",
    "                'well','give','user','value','without','know','abcde',\n",
    "                'any','does','exampl','try','ani','do','doe','e','v','j'\n",
    "                'file','will', 'hi', 'hello','question']   \n",
    "stop_words = stops.union(set(custom_words))\n",
    "\n",
    "def body_clean(title, text):\n",
    "    body = [title + text]\n",
    "    body = ''.join(body)\n",
    "    body = re.sub('\\+\\+','plusplus', body) \n",
    "    body = re.sub('#','sharp', body)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", body)  \n",
    "    words = letters_only.lower().split()         \n",
    "    words = [w for w in words if not w in stop_words] \n",
    "    wnl = WordNetLemmatizer()\n",
    "    words = [wnl.lemmatize(w) for w in words]\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    words = [stemmer.stem(word) for word in words]      \n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return ( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_prediction(body):\n",
    "    X = pd.Series(body)\n",
    "    tfidf = load('tfidf_model.joblib')\n",
    "#     tfidf = joblib.load('tfidf_model.sav') # TF-IDF Vectorization\n",
    "    X = tfidf.transform(X)\n",
    "    svc_model = load('finalized_model.joblib')\n",
    "#     svc_model = joblib.load('finalized_model.sav') # Linear SVC model\n",
    "    pred_svc = svc_model.predict(X)\n",
    "    mlb = load('multilabelling_model.joblib')\n",
    "#     mlb = joblib.load('multilabelling_model.sav') # Multilabelled tags\n",
    "    return mlb.inverse_transform(pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imput1 = 'Hi my name is Juan!'\n",
    "imput2 = 'I want to know if my mom loves me or not but I use python and C++ to ask my java question'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_output(imput1,imput2):\n",
    "    body = body_clean(imput1,imput2)\n",
    "    outputs = tags_prediction(body)\n",
    "#     outputs = ''.join(outputs)\n",
    "#     outputs = re.sub('plusplus','\\+\\+', outputs) \n",
    "#     outputs = re.sub('sharp','#', outputs)\n",
    "#     outputs = outputs.split() \n",
    "    return \"{}\".format(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('cplusplus', 'java', 'python')]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_output(imput1,imput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
